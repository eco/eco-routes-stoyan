/**
 * @file deploy-contracts.ts
 *
 * This file is responsible for deploying smart contracts using deterministic
 * deployment (CREATE3) with specific salts derived from the package version.
 *
 * The deterministic deployment approach ensures that contracts with the same version
 * and salt will have the same address across different deployments and networks,
 * which is critical for cross-chain protocols.
 *
 * Key features:
 * - Supports deploying to multiple environments (production and pre-production)
 * - Uses different salts for different environments but in the same deployment process
 * - Generates production and pre-production addresses from semantic version
 * - Stores deployment results for consumption by client libraries
 *
 * The deployment process:
 * 1. Computes salt values based on semantic version
 * 2. Creates a single results file for all deployments
 * 3. Deploys contracts to each environment with appropriate salt, skipping if already deployed
 * 4. Collects and combines results from all deployments
 * 5. Formats and saves deployment data to JSON for use in the package
 */

import { spawn } from 'child_process'
import path from 'path'
import fs from 'fs'
import { parse as parseCSV } from 'csv-parse/sync'
import { determineSalts } from '../utils/extract-salt'
import { getAddress } from 'viem'
import { SemanticContext } from './sr-prepare'
import {
  PATHS,
  ENV_VARS,
  getDeploymentResultsPath,
  getDeployedAddressesJsonPath,
  getBuildDirPath,
} from './constants'
import dotenv from 'dotenv'
import { Logger } from './helpers'
import { generateDeploymentFile } from './gen-bytecode'
import { promisify } from 'util'
dotenv.config()

/**
 * Helper function to execute a process and handle its outputs using async/await
 * @param command The command to execute
 * @param args Array of command arguments
 * @param options Options for the child process
 * @returns Promise that resolves to the exit code
 */
async function executeProcessAsync(
  command: string,
  args: string[],
  options: any
): Promise<number> {
  const execProcess = promisify((cmd: string, args: string[], options: any, callback: (err: Error | null, code: number) => void) => {
    const proc = spawn(cmd, args, options)

    proc.on('close', (code) => {
      callback(null, code || 0)
    })

    proc.on('error', (error) => {
      callback(error, 1)
    })
  })

  return await execProcess(command, args, options)
}

interface Contract {
  address: string
  name: string
  chainId: number
  environment?: string
  contractPath?: string
}

// Define the type for CSV parser records
interface DeploymentRecord {
  ChainID: string
  Environment: string
  ContractName: string
  ContractAddress: string
  ContractPath: string
}

interface DeploymentResult {
  contracts: Contract[]
  success: boolean
}

export async function deployRoutesContracts(
  context: SemanticContext,
  packageName: string,
): Promise<void> {
  const { nextRelease, logger, cwd } = context
  try {
    // Clean up existing build directory if it exists
    const buildDir = getBuildDirPath(cwd)
    if (fs.existsSync(buildDir)) {
      logger.log(`Deleting existing build directory: ${buildDir}`)
      fs.rmSync(buildDir, { recursive: true, force: true })
      logger.log('Build directory deleted successfully')
    }

    // Create build directory
    fs.mkdirSync(buildDir, { recursive: true })
    logger.log(`Created build directory: ${buildDir}`)

    // Determine salts based on version
    const { rootSalt, preprodRootSalt } = await determineSalts(
      nextRelease!.version,
      logger,
    )

    // Generate the deployment data
    const bytecodePath = path.join(buildDir, PATHS.DEPLOYMENT_BYTECODE_FILE)
    logger.log(`Generating bytecode deployment file at: ${bytecodePath}`)

    await generateDeploymentFile(
      [
        { name: 'default', value: rootSalt },
        { name: 'pre', value: preprodRootSalt },
      ],
      bytecodePath,
    )
    
    //Deploy the contracts using the generated bytecode
    logger.log('Deploying contracts...')
    await deployContracts(logger, cwd)

    // await deployToEnv([
    //   { salt: rootSalt, environment: 'production' },
    //   { salt: preprodRootSalt, environment: 'preprod' },
    // ], logger, cwd)

    // Deploy the generated deploymentAddresses
    await generateDeploymentAddressesJSON(context)
  } catch (error) {
    logger.error('❌ Contract deployment failed')
    logger.error((error as Error).message)
    throw error
  }
}

/**
 * Execute the deploy.sh script to deploy contracts
 * @param context Semantic release context
 * @returns Promise that resolves when deployment is complete
 */
async function generateDeploymentAddressesJSON(context: SemanticContext): Promise<void> {
  const { nextRelease, logger, cwd } = context
  logger.log('Creating the deployAddresses.json...')
  const resultsFile = getDeploymentResultsPath(cwd)

  try {
    if (!fs.existsSync(resultsFile)) {
      throw new Error(`Deployment results file not found at ${resultsFile}`)
    }

    logger.log(`Deployment results saved to ${resultsFile}`)

    // Convert deployment results to contract addresses JSON
    const contracts = parseDeploymentResults(resultsFile, logger)
    const contractsJson = processContractsForJson(contracts)

    // Save to deployed addresses JSON
    const deployedAddressesPath = getDeployedAddressesJsonPath(cwd)
    fs.writeFileSync(
      deployedAddressesPath,
      JSON.stringify(contractsJson, null, 2)
    )

    // Also generate verification data for contract verification
    // updateVerificationFile(cwd, contracts, logger)

    logger.log(`Contract addresses saved to ${deployedAddressesPath}`)
    logger.log('✅ Contract deployment completed successfully')
  } catch (error) {
    logger.error(`Deployment process failed: ${(error as Error).message}`)
    throw error
  }
}

/**
 * Deploy contracts using existing deployment infrastructure
 */
// async function deployToEnv(
//   logger: Logger,
//   cwd: string,
// ): Promise<void> {
//   // Check for required environment variables
//   const requiredEnvVars = [ENV_VARS.PRIVATE_KEY, ENV_VARS.ALCHEMY_API_KEY]
//   for (const envVar of requiredEnvVars) {
//     if (!process.env[envVar]) {
//       throw new Error(`Required environment variable ${envVar} is not set`)
//     }
//   }

//   // // Define output directory and ensure it exists
//   // const outputDir = path.join(cwd, PATHS.OUTPUT_DIR)
//   // const deployedContractFilePath = getDeployedAddressesJsonPath(cwd)
//   // const resultsFile = getDeploymentResultsPath(cwd)

//   // fs.mkdirSync(outputDir, { recursive: true })
//   // fs.mkdirSync(path.dirname(deployedContractFilePath), { recursive: true })

//   // // Initialize contracts collection
//   // let allContracts: Contract[] = []

//   // // Clean up the results file once at the beginning of all deployments
//   // // This ensures we have a single file with all deployment results
//   // if (fs.existsSync(resultsFile)) {
//   //   logger.log(`Cleaning up previous deployment results file: ${resultsFile}`)
//   //   fs.unlinkSync(resultsFile)
//   // }

//   // // Create an empty results file
//   // fs.writeFileSync(resultsFile, '', 'utf-8')
//   // logger.log(`Created empty deployment results file: ${resultsFile}`)

//   // // Deploy contracts for each environment
//   // for (const config of configs) {
//   //   logger.log(`Deploying ${config.environment} contracts...`)

//   // Deploy contracts and get results
//   // const result = await deployContracts(logger, cwd)

//   //   if (!result.success) {
//   //     throw new Error(`Deployment failed for ${config.environment} environment`)
//   //   }

//   //   // Add environment info to contracts
//   //   const contractsWithEnv = result.contracts.map((contract) => ({
//   //     ...contract,
//   //     environment: config.environment,
//   //   }))

//   //   allContracts = [...allContracts, ...contractsWithEnv]
//   // }

//   // // Save all contracts to JSON
//   // const contractsJson = processContractsForJson(allContracts)
//   // fs.writeFileSync(
//   //   deployedContractFilePath,
//   //   JSON.stringify(contractsJson, null, 2),
//   // )

//   // logger.log(`Contract addresses saved to ${deployedContractFilePath}`)
// }

/**
 * Process contracts array into the required JSON format based on CSV columns:
 * ChainID,Environment,ContractName,ContractAddress,ContractPath
 */
function processContractsForJson(
  contracts: Contract[],
): Record<string, Record<string, string>> {
  // Group by chain ID and environment
  const groupedContracts: Record<string, Contract[]> = {}

  for (const contract of contracts) {
    const key = `${contract.chainId}${contract.environment === 'default' ? '' : `-${contract.environment}`}`
    if (!groupedContracts[key]) {
      groupedContracts[key] = []
    }
    groupedContracts[key].push(contract)
  }

  // Convert to desired format
  return Object.fromEntries(
    Object.entries(groupedContracts).map(([key, contracts]) => {
      const names = contracts.map((c) => c.name)
      const addresses = contracts.map((c) => c.address)

      const contractMap: Record<string, string> = {}
      for (let i = 0; i < names.length; i++) {
        // Only add addresses that exist and are not empty strings
        if (addresses[i] && addresses[i].trim() !== '') {
          contractMap[names[i]] = getAddress(addresses[i])
        }
      }

      return [key, contractMap]
    }),
  )
}

/**
 * Deploy contracts using the MultiDeploy.sh script and return the results
 * @param salt The salt to use for deployment
 * @param logger Logger instance for output messages
 * @param cwd Current working directory
 * @param resultsFile Path to the results file
 * @returns DeploymentResult object with contracts and success status
 */
// async function deployContracts(
//   salt: string,
//   logger: Logger,
//   cwd: string,
//   resultsFile: string,
// ): Promise<DeploymentResult> {
//   // Path to the deployment script
//   const deployScriptPath = path.join(cwd, PATHS.DEPLOY_SCRIPT)
//   const outputDir = path.join(cwd, PATHS.OUTPUT_DIR)

//   if (!fs.existsSync(deployScriptPath)) {
//     throw new Error(`Deployment script not found at ${deployScriptPath}`)
//   }

//   logger.log(`Running deployment with salt: ${salt}`)

//   // Create output directory if it doesn't exist
//   fs.mkdirSync(outputDir, { recursive: true })

//   // Use the shared process execution utility
//   async function executeProcess(command: string, args: string[], env: NodeJS.ProcessEnv): Promise<number> {
//     return executeProcessAsync(command, args, {
//       env,
//       stdio: 'inherit',
//       shell: true,
//       cwd,
//     })
//   }

//   try {
//     // Run the deployment script
//     const exitCode = await executeProcess(deployScriptPath, [], {
//       ...process.env,
//       [ENV_VARS.SALT]: salt,
//       [ENV_VARS.RESULTS_FILE]: resultsFile,
//       [ENV_VARS.APPEND_RESULTS]: 'true', // Add a flag to indicate we want to append results
//     })

//     logger.log(`Deployment process exited with code ${exitCode}`)

//     if (exitCode !== 0) {
//       return { contracts: [], success: false }
//     }

//     // Read deployment results
//     if (fs.existsSync(resultsFile)) {
//       const contracts = parseDeploymentResults(resultsFile, logger)
//       return { contracts, success: true }
//     } else {
//       logger.error(`Deployment results file not found at ${resultsFile}`)
//       return { contracts: [], success: false }
//     }
//   } catch (error) {
//     logger.error(`Deployment process failed: ${(error as Error).message}`)
//     return { contracts: [], success: false }
//   }
// }

async function deployContracts(logger: Logger,
  cwd: string,) {
  const requiredEnvVars = [ENV_VARS.PRIVATE_KEY, ENV_VARS.ALCHEMY_API_KEY]
  for (const envVar of requiredEnvVars) {
    if (!process.env[envVar]) {
      throw new Error(`Required environment variable ${envVar} is not set`)
    }
  }
  // Use the shared process execution utility
  async function executeProcess(command: string, args: string[], env: NodeJS.ProcessEnv): Promise<number> {
    return executeProcessAsync(command, args, {
      env,
      stdio: 'inherit',
      shell: true,
      cwd,
    })
  }
  try {
    // Run the deployment script
    const exitCode = await executeProcess(PATHS.DEPLOY_BYTECODE_SCRIPT, [], {
      ...process.env,
    })

    logger.log(`Deployment process exited with code ${exitCode}`)
  } catch (error) {
    logger.error(`Deployment process failed: ${(error as Error).message}`)
    return { contracts: [], success: false }
  }
}

/**
 * Parse all deployment results from the results file using CSV library
 * New format: ChainID,Environment,ContractName,ContractAddress,ContractPath
 *
 * @param filePath - Path to the CSV file containing deployment results
 * @param logger - Logger instance for output messages
 * @returns Array of Contract objects parsed from the file
 */
function parseDeploymentResults(filePath: string, logger?: Logger): Contract[] {
  if (!fs.existsSync(filePath)) {
    logger?.log(`Deployment results file not found: ${filePath}`)
    return []
  }

  try {
    const fileContent = fs.readFileSync(filePath, 'utf-8')

    // Skip empty file
    if (!fileContent.trim()) {
      logger?.log(`Deployment results file is empty: ${filePath}`)
      return []
    }

    // CSV parse options
    const parseOptions = {
      columns: true, // Use first row as column names
      skip_empty_lines: true,
      trim: true,
      delimiter: ',', // Specify delimiter explicitly
      comment: '#', // Handle any comment lines in the file
    }

    // Parse CSV content
    const records = parseCSV(fileContent, parseOptions) as DeploymentRecord[]

    const contracts: Contract[] = []

    // Process each record in the new format
    for (const record of records) {
      const chainId = parseInt(record.ChainID, 10)
      const environment = record.Environment
      const contractName = record.ContractName
      const contractAddress = record.ContractAddress
      const contractPath = record.ContractPath

      // Skip undefined or empty addresses
      if (!contractAddress || contractAddress === 'undefined' || contractAddress.trim() === '') {
        logger?.log(`Skipping undefined address for contract ${contractName} on chain ${chainId}`)
        continue
      }

      contracts.push({
        name: contractName,
        address: contractAddress,
        chainId,
        environment,
        contractPath
      })
    }

    logger?.log(`Parsed ${contracts.length} contract addresses from deployment results`)
    return contracts
  } catch (error) {
    // Log error but don't crash the process
    if (logger) {
      logger.error(
        `Error parsing deployment results from ${filePath}: ${(error as Error).message}`,
      )
    } else {
      console.error(
        `Error parsing deployment results: ${(error as Error).message}`,
      )
    }
    return []
  }
}

/**
 * Creates verification mapping file with actual contract addresses after deployment
 * This simple file just maps chain IDs and contract names to actual addresses
 * The verification script will read this and the bytecode file to get all needed data
 * Format: ChainID,Environment,ContractName,ContractAddress,ContractPath
 * @param cwd Current working directory 
 * @param contracts Array of deployed contract objects
 * @param logger Logger instance
 */
function updateVerificationFile(cwd: string, contracts: Contract[], logger?: Logger): void {
  try {
    const outputDir = path.join(cwd, PATHS.OUTPUT_DIR)
    const verifyFilePath = path.join(outputDir, 'verify-data.txt')
    const bytecodePath = path.join(cwd, 'build', PATHS.DEPLOYMENT_BYTECODE_FILE)

    // Ensure output directory exists
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true })
      logger?.log(`Created output directory: ${outputDir}`)
    }

    // Create a new verification file with actual addresses
    logger?.log(`Creating verification data file at ${verifyFilePath}`)

    // Check if bytecode file exists
    if (!fs.existsSync(bytecodePath)) {
      logger?.error(`Bytecode file not found at ${bytecodePath}`)
      return
    }

    // Generate verification lines based on deployed contracts
    const verificationLines: string[] = []

    // Group contracts by environment, chain ID, and contract name for easier lookup
    // This ensures we preserve all environments and don't overwrite any
    const contractsByEnvChainName = new Map<string, Map<string, Map<string, Contract>>>()

    for (const contract of contracts) {
      const environment = contract.environment || 'default'
      const chainId = contract.chainId.toString()
      const contractName = contract.name

      // Create nested maps as needed
      if (!contractsByEnvChainName.has(environment)) {
        contractsByEnvChainName.set(environment, new Map<string, Map<string, Contract>>())
      }

      const envMap = contractsByEnvChainName.get(environment)!

      if (!envMap.has(chainId)) {
        envMap.set(chainId, new Map<string, Contract>())
      }

      const chainMap = envMap.get(chainId)!
      chainMap.set(contractName, contract)
    }

    // Create an array to collect all verification entries
    // Each entry is: { chainId, environment, contractName, contractAddress, contractPath }
    const verificationEntries: Array<{
      chainId: string
      environment: string
      contractName: string
      contractAddress: string
      contractPath: string
    }> = []

    // First, collect all entries - this preserves all environment/chain combinations
    for (const [environment, envMap] of contractsByEnvChainName.entries()) {
      for (const [chainId, contractsMap] of envMap.entries()) {
        for (const [contractName, contract] of contractsMap.entries()) {
          // Use contract path from the contract object if available, otherwise use default pattern
          const contractPath = contract.contractPath || `contracts/${contractName}.sol:${contractName}`

          // Add to verification entries
          verificationEntries.push({
            chainId,
            environment,
            contractName,
            contractAddress: contract.address,
            contractPath
          })

          logger?.log(`Prepared verification data for ${contractName} on chain ${chainId} in environment ${environment} with address ${contract.address}`)
        }
      }
    }

    // Sort entries to get a consistent output (by chainId then contractName)
    verificationEntries.sort((a, b) => {
      // First sort by chainId
      if (a.chainId !== b.chainId) {
        return parseInt(a.chainId) - parseInt(b.chainId)
      }
      // Then by environment
      if (a.environment !== b.environment) {
        return a.environment.localeCompare(b.environment)
      }
      // Then by contract name
      return a.contractName.localeCompare(b.contractName)
    })

    // Add header line
    verificationLines.push("ChainID,Environment,ContractName,ContractAddress,ContractPath")

    // Generate the verification lines - format matching the CSV
    // ChainID,Environment,ContractName,ContractAddress,ContractPath
    for (const entry of verificationEntries) {
      verificationLines.push(`${entry.chainId},${entry.environment},${entry.contractName},${entry.contractAddress},${entry.contractPath}`)
    }

    logger?.log(`Generated ${verificationLines.length - 1} verification entries sorted by chain ID and contract name`)

    // Write verification data to file
    fs.writeFileSync(verifyFilePath, verificationLines.join('\n'))

    // Log the results, showing first few entries for verification
    logger?.log(`Verification data created at ${verifyFilePath} with ${verificationLines.length - 1} entries`)

    // Debug log the first few entries (up to 3)
    const samplesToShow = Math.min(3, verificationLines.length - 1)
    if (samplesToShow > 0) {
      logger?.log(`First ${samplesToShow} verification entries (of ${verificationLines.length - 1} total):`)
      for (let i = 1; i <= samplesToShow; i++) { // Start at 1 to skip header
        const parts = verificationLines[i].split(',')
        logger?.log(`  - Chain ${parts[0]}, Environment ${parts[1]}, Contract ${parts[2]}, Address ${parts[3]}`)
      }
    }

  } catch (error) {
    logger?.error(`Failed to create verification file: ${(error as Error).message}`)
  }
}